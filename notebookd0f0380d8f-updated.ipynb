{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\nimport os\nimport cv2\nimport numpy as np\nfrom random import shuffle\nimport pandas as pd\nfrom PIL import Image as im\nfrom matplotlib import pyplot as plt\nimport torch.nn as nn\nimport torchvision.transforms as T\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nimport cv2 as cv\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport gc\nimport random","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:25.147685Z","iopub.execute_input":"2022-12-22T19:12:25.148090Z","iopub.status.idle":"2022-12-22T19:12:25.155133Z","shell.execute_reply.started":"2022-12-22T19:12:25.148053Z","shell.execute_reply":"2022-12-22T19:12:25.153957Z"},"trusted":true},"execution_count":216,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/nn23-sports-image-classification/Train'\ntest_dir = '/kaggle/input/nn23-sports-image-classification/Test'\nL = 0.0001 # perhaps change\nImgSize = 224\nnum_classes = 6\nepochs = 500\nbatchSize = 64\nG_Cdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(G_Cdevice)","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:25.198581Z","iopub.execute_input":"2022-12-22T19:12:25.199657Z","iopub.status.idle":"2022-12-22T19:12:25.206267Z","shell.execute_reply.started":"2022-12-22T19:12:25.199620Z","shell.execute_reply":"2022-12-22T19:12:25.205147Z"},"trusted":true},"execution_count":217,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef create_label(image_name): # create label from image name\n    word_label = image_name.split('_')[0]\n    sports = ['Basketball', 'Football' , 'Rowing', 'Swimming', 'Tennis', 'Yoga']\n    for s in range (len(sports)):\n        if word_label == sports[s]:\n            return s\n\n        ","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:25.222277Z","iopub.execute_input":"2022-12-22T19:12:25.223045Z","iopub.status.idle":"2022-12-22T19:12:25.228350Z","shell.execute_reply.started":"2022-12-22T19:12:25.223011Z","shell.execute_reply":"2022-12-22T19:12:25.227232Z"},"trusted":true},"execution_count":218,"outputs":[]},{"cell_type":"code","source":"def changeExtention():\n    \n    for img in tqdm(os.listdir(train_dir)):\n        path = os.path.join(train_dir, img)\n        ext = img.split('.')\n        if ext[-1]=='png':\n            img_data = im.open(path)\n            img_data.save(os.path.join(new_path, ext[0]+'.jpg'))\n        else:\n            img_data = im.open(path)\n            img_data.save(os.path.join(new_path, img))\n# this function: change all png images to jpg images","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:25.277664Z","iopub.execute_input":"2022-12-22T19:12:25.278258Z","iopub.status.idle":"2022-12-22T19:12:25.285711Z","shell.execute_reply.started":"2022-12-22T19:12:25.278224Z","shell.execute_reply":"2022-12-22T19:12:25.284664Z"},"trusted":true},"execution_count":219,"outputs":[]},{"cell_type":"code","source":"new_dir = \"new_train\"\nnew_path = os.path.join(\"/kaggle/working\", new_dir)\nif not os.path.exists(new_path):\n    os.mkdir(new_path, mode = 0o666)\n    changeExtention()\n    print(\"done converting\")\nprint(new_path)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:25.314058Z","iopub.execute_input":"2022-12-22T19:12:25.314314Z","iopub.status.idle":"2022-12-22T19:12:25.320758Z","shell.execute_reply.started":"2022-12-22T19:12:25.314290Z","shell.execute_reply":"2022-12-22T19:12:25.319480Z"},"trusted":true},"execution_count":220,"outputs":[{"name":"stdout","text":"/kaggle/working/new_train\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#global trainingData\n#train_dir = new_path\ndef preproces():\n    preprocess = T.Compose([\n           T.Resize((ImgSize,ImgSize)),\n#            T.CenterCrop(ImgSize),\n           T.ToTensor(),\n           T.Normalize(\n               mean=[0.4914, 0.4822, 0.4465],\n               std=[0.2023, 0.1994, 0.2010]\n           )\n    ])\n    return preprocess\n\n\ndef LoadTrainingData():\n    global training_data\n    training_data = list()\n    #trainingData = list()\n    for img in tqdm(os.listdir(train_dir)):\n        path = os.path.join(train_dir, img)\n        img_data = im.open(path)       \n        preproceses = preproces()\n        img_data = preproceses(img_data)\n        training_data.append([img_data, create_label(img)])\n        #trainingData.append([img_data, create_label(img)])\n    #trainingData = training_data\n    #print(len(trainingData))\n    shuffle(training_data)\n    np.save('train_data.npy', training_data)\n    return training_data\n\n\ndef LoadTestingData():\n    testing_data=[]\n    imgName=[]\n    for img in tqdm(os.listdir(test_dir)): \n        path = os.path.join(test_dir, img)\n        imgName.append(img)\n        img_data = im.open(path)\n        preproceses = preproces()\n        img_data = preproceses(img_data)\n        testing_data.append(img_data)\n#         shuffle(testing_data)\n    np.save('test_data.npy', testing_data)\n    \n    return testing_data, imgName\n","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:25.376057Z","iopub.execute_input":"2022-12-22T19:12:25.376797Z","iopub.status.idle":"2022-12-22T19:12:25.385701Z","shell.execute_reply.started":"2022-12-22T19:12:25.376763Z","shell.execute_reply":"2022-12-22T19:12:25.384856Z"},"trusted":true},"execution_count":221,"outputs":[]},{"cell_type":"code","source":"\nif (os.path.exists('train_data.npy')): # If we have already created the dataset:\n    training_data =np.load('train_data.npy',allow_pickle=True)\n#    train_dir = new_path\nelse: # If dataset is not created:\n\n    training_data = LoadTrainingData()\n    print(len(training_data))\n","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:25.426832Z","iopub.execute_input":"2022-12-22T19:12:25.427370Z","iopub.status.idle":"2022-12-22T19:12:26.169469Z","shell.execute_reply.started":"2022-12-22T19:12:25.427344Z","shell.execute_reply":"2022-12-22T19:12:26.168382Z"},"trusted":true},"execution_count":222,"outputs":[]},{"cell_type":"code","source":"#training_data = pd.DataFrame(training_data)\ntraining = training_data\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:26.173225Z","iopub.execute_input":"2022-12-22T19:12:26.175327Z","iopub.status.idle":"2022-12-22T19:12:26.183233Z","shell.execute_reply.started":"2022-12-22T19:12:26.175296Z","shell.execute_reply":"2022-12-22T19:12:26.182243Z"},"trusted":true},"execution_count":223,"outputs":[]},{"cell_type":"code","source":"\nX_train = ([i[0] for i in training])\ny_train = [i[1] for i in training]\nsplit =1300\nvalSet=381\nXvalid = X_train[split:]\nyvalid = y_train[split:]\n\nyvalid =torch.tensor(yvalid,device='cuda')\nyvalid =yvalid.reshape([valSet,1])\n","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:26.186442Z","iopub.execute_input":"2022-12-22T19:12:26.187415Z","iopub.status.idle":"2022-12-22T19:12:26.200572Z","shell.execute_reply.started":"2022-12-22T19:12:26.187377Z","shell.execute_reply":"2022-12-22T19:12:26.199649Z"},"trusted":true},"execution_count":224,"outputs":[]},{"cell_type":"code","source":"# split =1300\n# valSet=381\n# training = training_data\n# testing = testing_data\n# type(testing[0])\n# Xtrain = ([i[0] for i in training])\n# ytrain = [i[1] for i in training]\n\n# Xvalid = Xtrain[split:]\n# yvalid = ytrain[split:]\n\n# yvalid =torch.tensor(yvalid,device='cuda')\n# yvalid =yvalid.reshape([valSet,1])\n\n# training = training_data[:split]#.tolist()\n","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:26.203352Z","iopub.execute_input":"2022-12-22T19:12:26.204390Z","iopub.status.idle":"2022-12-22T19:12:26.210184Z","shell.execute_reply.started":"2022-12-22T19:12:26.204354Z","shell.execute_reply":"2022-12-22T19:12:26.209045Z"},"trusted":true},"execution_count":225,"outputs":[]},{"cell_type":"code","source":"Horizontal_Flipping_Transformation = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(p=1) \n])\n\nColor_Transformation = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ColorJitter(brightness=(0.1,0.6), contrast=1,saturation=0, hue=0.4)\n    #transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)\n])\n\nVertical_Flipping_Transformation = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomVerticalFlip(p=1) \n])\n\nRotate_Transformation = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomRotation(degrees=80)\n])\ngrayscale = transforms.Compose([  \n    transforms.ToPILImage(),\n    transforms.Grayscale(num_output_channels=1)\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:26.212007Z","iopub.execute_input":"2022-12-22T19:12:26.212340Z","iopub.status.idle":"2022-12-22T19:12:26.226532Z","shell.execute_reply.started":"2022-12-22T19:12:26.212307Z","shell.execute_reply":"2022-12-22T19:12:26.225546Z"},"trusted":true},"execution_count":226,"outputs":[]},{"cell_type":"code","source":"\n\n\n\ndef make_augmentation(training_data):\n    a = ((len(training_data)-1)/4)\n    augment1=random.randint(0,a)\n    print(augment1)\n    augment2=random.randint(0,a)\n    print(augment2)\n    augment3=random.randint(0,a)\n    print(augment3)\n    augment4=random.randint(0,a)\n    print(augment4)\n    augment5=random.randint(0,a)\n    print(augment5)\n\n    print(len(training_data))\n    #training_data_ = list()\n    #training_data = training_data.tolist()\n    i=0\n    for img in tqdm(os.listdir(train_dir)):\n        if i< augment1:\n            img_data = cv.imread(os.path.join(train_dir, img))[:,:,::-1]\n            Flipping_Img1 = Horizontal_Flipping_Transformation(img_data)\n            preproceses_ = preproces()\n            Flipping_Img1 = preproceses_(Flipping_Img1)\n            training_data.append([Flipping_Img1, create_label(img)])\n        #plt.imshow(Flipping_Img1)\n        #plt.show()\n#         elif i> augment1 & i < augment1+ augment2:\n#             img_data = cv.imread(os.path.join(train_dir, img))[:,:,::-1]\n#             Flipping_Img2 = Vertical_Flipping_Transformation(img_data)\n#             preproceses_ = preproces()\n#             Flipping_Img2 = preproceses_(Flipping_Img2)\n#             training_data.append([Flipping_Img2, create_label(img)])\n        #plt.imshow(Flipping_Img2)\n        #plt.show()\n        elif i > augment1 & i < augment1+ augment2:\n            img_data = cv.imread(os.path.join(train_dir, img))[:,:,::-1]\n            Transformed_Img = Color_Transformation(img_data)\n            preproceses_ = preproces()\n            Transformed_Img = preproceses_(Transformed_Img)\n            training_data.append([Transformed_Img, create_label(img)])\n        #plt.imshow(Transformed_Img)\n        #plt.show()\n        elif i> augment1+ augment2 & i < augment1+ augment2+ augment3:\n            img_data = cv.imread(os.path.join(train_dir, img))[:,:,::-1]        \n            Rotated_Img = Rotate_Transformation(img_data)\n            preproceses_ = preproces()\n            Rotated_Img = preproceses_(Rotated_Img)\n            training_data.append([Rotated_Img, create_label(img)])\n        elif i> augment1+ augment2 + augment3 & i < augment1+ augment2+ augment3+ augment4:\n            img_data = cv.imread(os.path.join(train_dir, img))[:,:,::-1]        \n            grayIMG = grayscale(img_data)\n            preproceses_ = preproces()\n            grayIMG = preproceses_(grayIMG)\n            training_data.append([grayIMG, create_label(img)])\n        #plt.imshow(Rotated_Img)\n        #plt.show()    \n        if i == augment1+ augment2+ augment3+ augment4:\n            break\n        i = i +1\n        if i==200:\n            break\n    return training_data\n\nif (os.path.exists('train_data12.npy')): # If we have already created the dataset:\n    training_data =np.load('train_data12.npy',allow_pickle=True)\nelse:\n    training_data = make_augmentation(training_data)\n    shuffle(training_data)\n    np.save('train_data12.npy', training_data)\n    \n\nprint(len(training_data))\ntraining = training_data\n","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:26.228043Z","iopub.execute_input":"2022-12-22T19:12:26.228382Z","iopub.status.idle":"2022-12-22T19:12:27.039287Z","shell.execute_reply.started":"2022-12-22T19:12:26.228347Z","shell.execute_reply":"2022-12-22T19:12:27.038238Z"},"trusted":true},"execution_count":227,"outputs":[{"name":"stdout","text":"1881\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train = ([i[0] for i in training])\ny_train = [i[1] for i in training]\ny_train =torch.tensor(y_train,device='cuda')\ny_train =y_train.reshape([len(X_train),1])","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:27.040984Z","iopub.execute_input":"2022-12-22T19:12:27.041367Z","iopub.status.idle":"2022-12-22T19:12:27.052518Z","shell.execute_reply.started":"2022-12-22T19:12:27.041329Z","shell.execute_reply":"2022-12-22T19:12:27.051313Z"},"trusted":true},"execution_count":228,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class block(nn.Module):\n    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n        super(block, self).__init__()\n        self.expansion = 1\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        \n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,stride=stride,padding=1,bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n     \n        self.relu = nn.ReLU()\n        self.identity_downsample = identity_downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n\n        if self.identity_downsample is not None:\n            identity = self.identity_downsample(identity)\n\n        x += identity\n        x = self.relu(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:27.054262Z","iopub.execute_input":"2022-12-22T19:12:27.055221Z","iopub.status.idle":"2022-12-22T19:12:27.064826Z","shell.execute_reply.started":"2022-12-22T19:12:27.055180Z","shell.execute_reply":"2022-12-22T19:12:27.064016Z"},"trusted":true},"execution_count":229,"outputs":[]},{"cell_type":"code","source":"class ResNet(nn.Module):\n    def __init__(self, block, layers, image_channels=3, num_classes=6):\n        super(ResNet, self).__init__()\n        self.in_channels = 64\n        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # Essentially the entire ResNet architecture are in these 4 lines below\n        self.layer1 = self._make_layer(block, layers[0],64, out_channels=64, stride=1)\n        self.layer2 = self._make_layer(block, layers[1],64,out_channels=128, stride=2)\n        self.layer3 = self._make_layer(block, layers[2],128,out_channels=256, stride=2)\n        self.layer4 = self._make_layer(block, layers[3],256 ,out_channels=512, stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * 1, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.shape[0], -1)\n        #x = x.reshape(x.shape[0], -1)\n        #x = x.view(2048)\n        x = self.fc(x)\n\n        return x\n    def _make_layer(self, block, num_residual_blocks,in_channels, out_channels, stride):\n        \n        identity_downsample = None\n        if stride != 1:\n            identity_downsample = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1,bias=False), \n            nn.BatchNorm2d(out_channels)\n        )\n        layers=[]\n        layers.append(block(in_channels, out_channels, identity_downsample, stride))\n        layers.append(block(out_channels, out_channels))\n        return nn.Sequential(*layers)\n    \n    \n#     def _make_layer(self, block, num_residual_blocks, out_channels, stride):\n#         identity_downsample = None\n        \n\n#         # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n#         # we need to adapt the Identity (skip connection) so it will be able to be added\n#         # to the layer that's ahead\n        \n#         #make sure of for loop (intermediate_channels * 4)\n#         #use of downsample\n#         if stride != 1 or self.in_channels != out_channels*1:\n#             identity_downsample = nn.Sequential(\n#                 nn.Conv2d(self.in_channels,out_channels * 1,kernel_size=1,stride = stride,bias=False),\n#                 nn.BatchNorm2d(out_channels * 1),\n#             )\n#         layers = []\n#         self.in_channels= out_channels\n#         layers.append(block(self.in_channels, out_channels, identity_downsample, stride))\n\n#         # The expansion size is always 4 for ResNet 50,101,152\n#         #self.in_channels = out_channels * 1\n\n#         # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n#         # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n#         # and also same amount of channels.\n#         #self.in_channels = out_channels\n#         for i in range(num_residual_blocks -1):\n#             layers.append(block(self.in_channels,out_channels))\n\n#         return nn.Sequential(*layers)","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:27.066443Z","iopub.execute_input":"2022-12-22T19:12:27.066789Z","iopub.status.idle":"2022-12-22T19:12:27.083165Z","shell.execute_reply.started":"2022-12-22T19:12:27.066756Z","shell.execute_reply":"2022-12-22T19:12:27.082326Z"},"trusted":true},"execution_count":230,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img=Xtrain[4]\n# img = img.permute(1, 2, 0).numpy()\n# plt.imshow(img)\n# print(ytrain[4])","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:27.089634Z","iopub.execute_input":"2022-12-22T19:12:27.089972Z","iopub.status.idle":"2022-12-22T19:12:27.098436Z","shell.execute_reply.started":"2022-12-22T19:12:27.089940Z","shell.execute_reply":"2022-12-22T19:12:27.097375Z"},"trusted":true},"execution_count":231,"outputs":[]},{"cell_type":"code","source":"# batch=random.randint(0,len(X_train_))\n# batch","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:27.102586Z","iopub.execute_input":"2022-12-22T19:12:27.102970Z","iopub.status.idle":"2022-12-22T19:12:27.111288Z","shell.execute_reply.started":"2022-12-22T19:12:27.102896Z","shell.execute_reply":"2022-12-22T19:12:27.110202Z"},"trusted":true},"execution_count":232,"outputs":[]},{"cell_type":"code","source":"# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\n\n# Train the model\n\ndef start_trainRes(ytrain_,Xtrain_):\n    model = ResNet(block, [2, 2, 2, 2],3,6).to(G_Cdevice)\n    #loss = nn.MSELoss()\n    loss = nn.CrossEntropyLoss()\n    #optimizer = torch.optim.Adam(model.parameters(), lr=L,  weight_decay = 0.000000001)\n    optimizer = torch.optim.SGD(model.parameters(), lr=L, weight_decay = 0.001, momentum = 0.9)  \n    global output\n    print(len(Xtrain_))\n    total=0\n    correct=0\n    for each_epoch in range(epochs):\n        batch=random.randint(0,len(Xtrain_))\n        b=0\n        global error\n        for ind in range(batch,len(Xtrain_)):\n            if b == batchSize:\n                break\n            b+=1 \n            Xtrain_[ind] = Xtrain_[ind].to(G_Cdevice)\n            ytrain_[ind] = ytrain_[ind].to(G_Cdevice)\n            output = model.forward(Xtrain_[ind].unsqueeze(0))\n            error = loss(output,ytrain_[ind])\n            optimizer.zero_grad()\n            error.backward()\n            optimizer.step()\n#             _, predicted = torch.max(output.data, 1)\n#             total += ytrain_[i].size(0)\n#             correct += (predicted == ytrain_[i].to(G_Cdevice)).sum().item()\n#             del X_train[ind], y_train_[ind], output\n#             torch.cuda.empty_cache()\n#             gc.collect()\n        print(\"Epoch: \",each_epoch)\n        print(\"Error: \",error.item())\n    return model    \n\nmodelR = start_trainRes(y_train,X_train)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:12:27.113152Z","iopub.execute_input":"2022-12-22T19:12:27.113506Z","iopub.status.idle":"2022-12-22T19:19:31.625299Z","shell.execute_reply.started":"2022-12-22T19:12:27.113471Z","shell.execute_reply":"2022-12-22T19:19:31.624197Z"},"trusted":true},"execution_count":233,"outputs":[{"name":"stdout","text":"1881\nEpoch:  0\nError:  1.2446298599243164\nEpoch:  1\nError:  2.17830753326416\nEpoch:  2\nError:  1.7874705791473389\nEpoch:  3\nError:  2.0429420471191406\nEpoch:  4\nError:  1.4447808265686035\nEpoch:  5\nError:  1.7806296348571777\nEpoch:  6\nError:  1.3185456991195679\nEpoch:  7\nError:  1.6900146007537842\nEpoch:  8\nError:  0.7237643003463745\nEpoch:  9\nError:  1.639716386795044\nEpoch:  10\nError:  1.219748616218567\nEpoch:  11\nError:  1.8804198503494263\nEpoch:  12\nError:  2.057985305786133\nEpoch:  13\nError:  2.1625375747680664\nEpoch:  14\nError:  1.8924392461776733\nEpoch:  15\nError:  0.9017083644866943\nEpoch:  16\nError:  0.49274832010269165\nEpoch:  17\nError:  1.3548816442489624\nEpoch:  18\nError:  0.4167132079601288\nEpoch:  19\nError:  0.8575946092605591\nEpoch:  20\nError:  0.9448845386505127\nEpoch:  21\nError:  0.24890705943107605\nEpoch:  22\nError:  0.25270015001296997\nEpoch:  23\nError:  0.39513739943504333\nEpoch:  24\nError:  1.5763561725616455\nEpoch:  25\nError:  0.7665671110153198\nEpoch:  26\nError:  0.25105348229408264\nEpoch:  27\nError:  1.5863666534423828\nEpoch:  28\nError:  2.5181496143341064\nEpoch:  29\nError:  0.8253177404403687\nEpoch:  30\nError:  1.1851134300231934\nEpoch:  31\nError:  1.9613498449325562\nEpoch:  32\nError:  1.7633212804794312\nEpoch:  33\nError:  2.0737111568450928\nEpoch:  34\nError:  2.3718385696411133\nEpoch:  35\nError:  1.7803246974945068\nEpoch:  36\nError:  1.5486881732940674\nEpoch:  37\nError:  1.8955261707305908\nEpoch:  38\nError:  1.466768741607666\nEpoch:  39\nError:  0.30968135595321655\nEpoch:  40\nError:  1.3456838130950928\nEpoch:  41\nError:  1.5210658311843872\nEpoch:  42\nError:  0.9188153743743896\nEpoch:  43\nError:  1.6842132806777954\nEpoch:  44\nError:  1.2901525497436523\nEpoch:  45\nError:  1.2633414268493652\nEpoch:  46\nError:  2.0105819702148438\nEpoch:  47\nError:  1.523160457611084\nEpoch:  48\nError:  1.3363476991653442\nEpoch:  49\nError:  0.29462960362434387\nEpoch:  50\nError:  1.4283238649368286\nEpoch:  51\nError:  0.41678935289382935\nEpoch:  52\nError:  0.33997058868408203\nEpoch:  53\nError:  4.3511176109313965\nEpoch:  54\nError:  1.185825228691101\nEpoch:  55\nError:  2.506303310394287\nEpoch:  56\nError:  0.4112158715724945\nEpoch:  57\nError:  1.0607564449310303\nEpoch:  58\nError:  1.7746350765228271\nEpoch:  59\nError:  0.33445385098457336\nEpoch:  60\nError:  1.764091968536377\nEpoch:  61\nError:  0.03920084610581398\nEpoch:  62\nError:  0.3661178648471832\nEpoch:  63\nError:  2.441114902496338\nEpoch:  64\nError:  0.8393320441246033\nEpoch:  65\nError:  0.12102556228637695\nEpoch:  66\nError:  0.0813782811164856\nEpoch:  67\nError:  0.8390615582466125\nEpoch:  68\nError:  1.3744693994522095\nEpoch:  69\nError:  0.25007399916648865\nEpoch:  70\nError:  0.3610382080078125\nEpoch:  71\nError:  1.9874670505523682\nEpoch:  72\nError:  0.6001259684562683\nEpoch:  73\nError:  0.20697978138923645\nEpoch:  74\nError:  1.815018892288208\nEpoch:  75\nError:  0.18411825597286224\nEpoch:  76\nError:  0.5351828932762146\nEpoch:  77\nError:  0.977436363697052\nEpoch:  78\nError:  0.6337188482284546\nEpoch:  79\nError:  2.45133113861084\nEpoch:  80\nError:  0.7062088847160339\nEpoch:  81\nError:  2.024596929550171\nEpoch:  82\nError:  0.10691835731267929\nEpoch:  83\nError:  0.2641938030719757\nEpoch:  84\nError:  0.07430625706911087\nEpoch:  85\nError:  0.044889144599437714\nEpoch:  86\nError:  1.9355911016464233\nEpoch:  87\nError:  1.068207025527954\nEpoch:  88\nError:  0.12708574533462524\nEpoch:  89\nError:  0.5455945730209351\nEpoch:  90\nError:  0.4459756016731262\nEpoch:  91\nError:  0.03562326356768608\nEpoch:  92\nError:  0.6697948575019836\nEpoch:  93\nError:  1.7956626415252686\nEpoch:  94\nError:  0.943023145198822\nEpoch:  95\nError:  0.12364090234041214\nEpoch:  96\nError:  0.2107803076505661\nEpoch:  97\nError:  0.1143447533249855\nEpoch:  98\nError:  3.4049103260040283\nEpoch:  99\nError:  0.6111395955085754\nEpoch:  100\nError:  0.9758706092834473\nEpoch:  101\nError:  0.13101768493652344\nEpoch:  102\nError:  0.21354129910469055\nEpoch:  103\nError:  0.5373093485832214\nEpoch:  104\nError:  0.15931767225265503\nEpoch:  105\nError:  0.06540533155202866\nEpoch:  106\nError:  1.4698126316070557\nEpoch:  107\nError:  0.39576029777526855\nEpoch:  108\nError:  2.362203359603882\nEpoch:  109\nError:  0.08531204611063004\nEpoch:  110\nError:  0.2902388274669647\nEpoch:  111\nError:  0.008833969943225384\nEpoch:  112\nError:  1.527221441268921\nEpoch:  113\nError:  0.015217045322060585\nEpoch:  114\nError:  0.8835859894752502\nEpoch:  115\nError:  0.5727928876876831\nEpoch:  116\nError:  0.14589953422546387\nEpoch:  117\nError:  0.269408643245697\nEpoch:  118\nError:  0.5835252404212952\nEpoch:  119\nError:  0.9232711791992188\nEpoch:  120\nError:  1.0940473079681396\nEpoch:  121\nError:  0.24094678461551666\nEpoch:  122\nError:  1.7209374904632568\nEpoch:  123\nError:  0.12326201051473618\nEpoch:  124\nError:  0.2610928416252136\nEpoch:  125\nError:  0.10979054123163223\nEpoch:  126\nError:  0.22589930891990662\nEpoch:  127\nError:  0.6235062479972839\nEpoch:  128\nError:  0.27881360054016113\nEpoch:  129\nError:  0.12027273327112198\nEpoch:  130\nError:  0.029893314465880394\nEpoch:  131\nError:  0.10890605300664902\nEpoch:  132\nError:  0.8756306767463684\nEpoch:  133\nError:  1.26657235622406\nEpoch:  134\nError:  0.2203839123249054\nEpoch:  135\nError:  0.011727792210876942\nEpoch:  136\nError:  0.508650541305542\nEpoch:  137\nError:  0.03705376386642456\nEpoch:  138\nError:  0.26277056336402893\nEpoch:  139\nError:  0.018388979136943817\nEpoch:  140\nError:  3.629404067993164\nEpoch:  141\nError:  0.07240564376115799\nEpoch:  142\nError:  0.21379248797893524\nEpoch:  143\nError:  0.049522362649440765\nEpoch:  144\nError:  0.021331291645765305\nEpoch:  145\nError:  0.09320958703756332\nEpoch:  146\nError:  5.167481899261475\nEpoch:  147\nError:  0.44636499881744385\nEpoch:  148\nError:  3.286613702774048\nEpoch:  149\nError:  1.0618966817855835\nEpoch:  150\nError:  0.08821249008178711\nEpoch:  151\nError:  0.014178610406816006\nEpoch:  152\nError:  2.428295135498047\nEpoch:  153\nError:  0.17718811333179474\nEpoch:  154\nError:  0.1893032044172287\nEpoch:  155\nError:  0.3466658592224121\nEpoch:  156\nError:  1.349515438079834\nEpoch:  157\nError:  0.1853761374950409\nEpoch:  158\nError:  2.1086130142211914\nEpoch:  159\nError:  0.1586938351392746\nEpoch:  160\nError:  0.008052030578255653\nEpoch:  161\nError:  0.12735289335250854\nEpoch:  162\nError:  1.3222898244857788\nEpoch:  163\nError:  0.5370201468467712\nEpoch:  164\nError:  0.04427690431475639\nEpoch:  165\nError:  0.049071528017520905\nEpoch:  166\nError:  0.018923580646514893\nEpoch:  167\nError:  0.529165506362915\nEpoch:  168\nError:  0.18663719296455383\nEpoch:  169\nError:  0.23147419095039368\nEpoch:  170\nError:  0.05992920696735382\nEpoch:  171\nError:  0.14396892488002777\nEpoch:  172\nError:  1.823072910308838\nEpoch:  173\nError:  1.16506826877594\nEpoch:  174\nError:  0.09790235012769699\nEpoch:  175\nError:  0.02441377565264702\nEpoch:  176\nError:  0.06522855907678604\nEpoch:  177\nError:  0.8732275366783142\nEpoch:  178\nError:  0.02194782719016075\nEpoch:  179\nError:  0.04611865058541298\nEpoch:  180\nError:  0.23423466086387634\nEpoch:  181\nError:  0.4743528962135315\nEpoch:  182\nError:  0.017002182081341743\nEpoch:  183\nError:  0.16516195237636566\nEpoch:  184\nError:  0.0726105347275734\nEpoch:  185\nError:  0.07810549437999725\nEpoch:  186\nError:  0.1119617447257042\nEpoch:  187\nError:  0.05923207476735115\nEpoch:  188\nError:  0.4063100218772888\nEpoch:  189\nError:  0.019513309001922607\nEpoch:  190\nError:  0.010618260130286217\nEpoch:  191\nError:  1.1936568021774292\nEpoch:  192\nError:  0.02679300121963024\nEpoch:  193\nError:  0.04232892394065857\nEpoch:  194\nError:  0.8884797692298889\nEpoch:  195\nError:  0.37133312225341797\nEpoch:  196\nError:  0.09110324829816818\nEpoch:  197\nError:  0.43153342604637146\nEpoch:  198\nError:  0.16834282875061035\nEpoch:  199\nError:  0.003304499201476574\nEpoch:  200\nError:  0.0035756006836891174\nEpoch:  201\nError:  0.23507530987262726\nEpoch:  202\nError:  0.17430320382118225\nEpoch:  203\nError:  0.0406484492123127\nEpoch:  204\nError:  0.00472239451482892\nEpoch:  205\nError:  0.04624158516526222\nEpoch:  206\nError:  0.017158864066004753\nEpoch:  207\nError:  0.10621678829193115\nEpoch:  208\nError:  0.03137627989053726\nEpoch:  209\nError:  0.19177713990211487\nEpoch:  210\nError:  0.44717109203338623\nEpoch:  211\nError:  0.12260830402374268\nEpoch:  212\nError:  0.4670509397983551\nEpoch:  213\nError:  0.027524825185537338\nEpoch:  214\nError:  0.06405968219041824\nEpoch:  215\nError:  0.04497314244508743\nEpoch:  216\nError:  0.057245492935180664\nEpoch:  217\nError:  0.006337781902402639\nEpoch:  218\nError:  0.003958248998969793\nEpoch:  219\nError:  0.128220796585083\nEpoch:  220\nError:  0.09199252724647522\nEpoch:  221\nError:  0.004123993683606386\nEpoch:  222\nError:  0.0476187989115715\nEpoch:  223\nError:  0.025660913437604904\nEpoch:  224\nError:  0.26492229104042053\nEpoch:  225\nError:  0.9504488110542297\nEpoch:  226\nError:  0.0010418231831863523\nEpoch:  227\nError:  0.02277456410229206\nEpoch:  228\nError:  0.5946418642997742\nEpoch:  229\nError:  0.40804290771484375\nEpoch:  230\nError:  0.09469803422689438\nEpoch:  231\nError:  0.9587488770484924\nEpoch:  232\nError:  0.012247240170836449\nEpoch:  233\nError:  0.04686490818858147\nEpoch:  234\nError:  0.3995901942253113\nEpoch:  235\nError:  0.027147842571139336\nEpoch:  236\nError:  0.007015003357082605\nEpoch:  237\nError:  0.029845645651221275\nEpoch:  238\nError:  0.06821559369564056\nEpoch:  239\nError:  0.033604737371206284\nEpoch:  240\nError:  0.06105940416455269\nEpoch:  241\nError:  0.029449164867401123\nEpoch:  242\nError:  0.009310754016041756\nEpoch:  243\nError:  0.022886188700795174\nEpoch:  244\nError:  1.2942912578582764\nEpoch:  245\nError:  0.007032759487628937\nEpoch:  246\nError:  0.0384177528321743\nEpoch:  247\nError:  1.07327401638031\nEpoch:  248\nError:  0.6938381195068359\nEpoch:  249\nError:  0.5397809743881226\nEpoch:  250\nError:  0.19417674839496613\nEpoch:  251\nError:  1.0828907489776611\nEpoch:  252\nError:  0.4136788249015808\nEpoch:  253\nError:  0.01536144781857729\nEpoch:  254\nError:  0.0937265008687973\nEpoch:  255\nError:  0.5270785093307495\nEpoch:  256\nError:  0.04205521196126938\nEpoch:  257\nError:  0.041486866772174835\nEpoch:  258\nError:  0.03302706778049469\nEpoch:  259\nError:  0.08247660100460052\nEpoch:  260\nError:  0.3016929030418396\nEpoch:  261\nError:  0.04735415056347847\nEpoch:  262\nError:  0.3818485140800476\nEpoch:  263\nError:  0.09536243230104446\nEpoch:  264\nError:  0.002481002826243639\nEpoch:  265\nError:  0.3461422324180603\nEpoch:  266\nError:  0.18559032678604126\nEpoch:  267\nError:  0.09159068018198013\nEpoch:  268\nError:  0.0016891986597329378\nEpoch:  269\nError:  0.2165389508008957\nEpoch:  270\nError:  0.05891338735818863\nEpoch:  271\nError:  1.1640115976333618\nEpoch:  272\nError:  0.4779476523399353\nEpoch:  273\nError:  0.644498884677887\nEpoch:  274\nError:  0.0043711354956030846\nEpoch:  275\nError:  0.0010484919184818864\nEpoch:  276\nError:  0.032903995364904404\nEpoch:  277\nError:  0.004785394296050072\nEpoch:  278\nError:  0.3968620002269745\nEpoch:  279\nError:  0.1239403560757637\nEpoch:  280\nError:  0.01275912206619978\nEpoch:  281\nError:  0.002423565834760666\nEpoch:  282\nError:  0.015458056703209877\nEpoch:  283\nError:  0.10992661863565445\nEpoch:  284\nError:  0.1357724815607071\nEpoch:  285\nError:  0.0025452144909650087\nEpoch:  286\nError:  0.0013665156438946724\nEpoch:  287\nError:  0.1739116758108139\nEpoch:  288\nError:  0.10912914574146271\nEpoch:  289\nError:  0.004308347124606371\nEpoch:  290\nError:  0.000494715350214392\nEpoch:  291\nError:  0.987370491027832\nEpoch:  292\nError:  0.12672916054725647\nEpoch:  293\nError:  0.025586899369955063\nEpoch:  294\nError:  0.3637286424636841\nEpoch:  295\nError:  0.013645230792462826\nEpoch:  296\nError:  0.03891836479306221\nEpoch:  297\nError:  0.0004003438516519964\nEpoch:  298\nError:  0.001995121594518423\nEpoch:  299\nError:  0.015884293243288994\nEpoch:  300\nError:  0.03559553995728493\nEpoch:  301\nError:  0.10159452259540558\nEpoch:  302\nError:  0.007916858419775963\nEpoch:  303\nError:  0.024287311360239983\nEpoch:  304\nError:  0.003544835140928626\nEpoch:  305\nError:  0.0008363801171071827\nEpoch:  306\nError:  0.1521117240190506\nEpoch:  307\nError:  0.08093300461769104\nEpoch:  308\nError:  0.004036019556224346\nEpoch:  309\nError:  0.13270622491836548\nEpoch:  310\nError:  0.028694307431578636\nEpoch:  311\nError:  0.05724672973155975\nEpoch:  312\nError:  0.05298316106200218\nEpoch:  313\nError:  0.018265966325998306\nEpoch:  314\nError:  0.00861168559640646\nEpoch:  315\nError:  0.0005530973430722952\nEpoch:  316\nError:  0.008903801441192627\nEpoch:  317\nError:  0.1786007136106491\nEpoch:  318\nError:  0.13061878085136414\nEpoch:  319\nError:  0.09586404263973236\nEpoch:  320\nError:  0.028509993106126785\nEpoch:  321\nError:  0.0006306566647253931\nEpoch:  322\nError:  0.3667370676994324\nEpoch:  323\nError:  0.04031279310584068\nEpoch:  324\nError:  0.005825446452945471\nEpoch:  325\nError:  0.009074398316442966\nEpoch:  326\nError:  0.031036224216222763\nEpoch:  327\nError:  0.01119510643184185\nEpoch:  328\nError:  0.003805302083492279\nEpoch:  329\nError:  0.014237727038562298\nEpoch:  330\nError:  0.36173370480537415\nEpoch:  331\nError:  0.11475680023431778\nEpoch:  332\nError:  0.0017997510731220245\nEpoch:  333\nError:  0.003591992659494281\nEpoch:  334\nError:  0.5707952380180359\nEpoch:  335\nError:  0.007162370719015598\nEpoch:  336\nError:  0.0036368912551552057\nEpoch:  337\nError:  0.31330767273902893\nEpoch:  338\nError:  0.035952214151620865\nEpoch:  339\nError:  0.03185617923736572\nEpoch:  340\nError:  0.0011438739020377398\nEpoch:  341\nError:  0.06270886212587357\nEpoch:  342\nError:  0.03455767780542374\nEpoch:  343\nError:  0.38906291127204895\nEpoch:  344\nError:  0.09435325115919113\nEpoch:  345\nError:  0.0007113072206266224\nEpoch:  346\nError:  0.8376612067222595\nEpoch:  347\nError:  0.001409133430570364\nEpoch:  348\nError:  0.008119196631014347\nEpoch:  349\nError:  0.001135062426328659\nEpoch:  350\nError:  0.013392254710197449\nEpoch:  351\nError:  0.006967059802263975\nEpoch:  352\nError:  0.004569208715111017\nEpoch:  353\nError:  0.11061843484640121\nEpoch:  354\nError:  0.013660634867846966\nEpoch:  355\nError:  0.010111181996762753\nEpoch:  356\nError:  0.001740013831295073\nEpoch:  357\nError:  0.007838324643671513\nEpoch:  358\nError:  0.05881863832473755\nEpoch:  359\nError:  0.03022334724664688\nEpoch:  360\nError:  0.0016763457097113132\nEpoch:  361\nError:  0.08031197637319565\nEpoch:  362\nError:  0.04360643029212952\nEpoch:  363\nError:  0.039078760892152786\nEpoch:  364\nError:  0.0005969410995021462\nEpoch:  365\nError:  0.002657931065186858\nEpoch:  366\nError:  0.0006833125371485949\nEpoch:  367\nError:  0.00955154001712799\nEpoch:  368\nError:  0.002007494680583477\nEpoch:  369\nError:  0.010816043242812157\nEpoch:  370\nError:  0.0006102845072746277\nEpoch:  371\nError:  0.0020542489364743233\nEpoch:  372\nError:  0.00975154060870409\nEpoch:  373\nError:  0.0064411889761686325\nEpoch:  374\nError:  0.0010949337156489491\nEpoch:  375\nError:  0.010888329707086086\nEpoch:  376\nError:  0.004926091525703669\nEpoch:  377\nError:  0.000666277133859694\nEpoch:  378\nError:  0.008963111788034439\nEpoch:  379\nError:  0.0003921216703020036\nEpoch:  380\nError:  0.005085746292024851\nEpoch:  381\nError:  0.001302585587836802\nEpoch:  382\nError:  0.002466019708663225\nEpoch:  383\nError:  0.0053206742741167545\nEpoch:  384\nError:  0.00219818577170372\nEpoch:  385\nError:  0.0047762589529156685\nEpoch:  386\nError:  0.01992741972208023\nEpoch:  387\nError:  1.0748635530471802\nEpoch:  388\nError:  0.016589906066656113\nEpoch:  389\nError:  0.039676547050476074\nEpoch:  390\nError:  0.02718891203403473\nEpoch:  391\nError:  0.029866356402635574\nEpoch:  392\nError:  0.008100276812911034\nEpoch:  393\nError:  0.005629163235425949\nEpoch:  394\nError:  0.0003104920033365488\nEpoch:  395\nError:  0.0184155460447073\nEpoch:  396\nError:  0.004937360994517803\nEpoch:  397\nError:  0.0009480987209826708\nEpoch:  398\nError:  0.04122916981577873\nEpoch:  399\nError:  0.01103182602673769\nEpoch:  400\nError:  0.0004970983718521893\nEpoch:  401\nError:  0.004119601100683212\nEpoch:  402\nError:  0.0011513754725456238\nEpoch:  403\nError:  0.007065430283546448\nEpoch:  404\nError:  0.004453502595424652\nEpoch:  405\nError:  0.004180858377367258\nEpoch:  406\nError:  0.01909317821264267\nEpoch:  407\nError:  0.001116010476835072\nEpoch:  408\nError:  0.0019828674849122763\nEpoch:  409\nError:  0.02384404093027115\nEpoch:  410\nError:  0.0064827618189156055\nEpoch:  411\nError:  0.005252490285784006\nEpoch:  412\nError:  0.0051322379149496555\nEpoch:  413\nError:  0.000750736624468118\nEpoch:  414\nError:  0.0009230881696566939\nEpoch:  415\nError:  0.0016551617300137877\nEpoch:  416\nError:  0.0034791436046361923\nEpoch:  417\nError:  0.0012354368809610605\nEpoch:  418\nError:  0.053893424570560455\nEpoch:  419\nError:  0.019251873716711998\nEpoch:  420\nError:  0.001341872732155025\nEpoch:  421\nError:  0.0033887361641973257\nEpoch:  422\nError:  0.0034786683972924948\nEpoch:  423\nError:  0.014971982687711716\nEpoch:  424\nError:  0.018963349983096123\nEpoch:  425\nError:  0.0038399784825742245\nEpoch:  426\nError:  0.0036507879849523306\nEpoch:  427\nError:  0.01488483976572752\nEpoch:  428\nError:  0.0008671099785715342\nEpoch:  429\nError:  0.0011963837314397097\nEpoch:  430\nError:  0.027546627447009087\nEpoch:  431\nError:  0.0007479969062842429\nEpoch:  432\nError:  0.02504352666437626\nEpoch:  433\nError:  0.02713322453200817\nEpoch:  434\nError:  0.00683600315824151\nEpoch:  435\nError:  0.007075728382915258\nEpoch:  436\nError:  0.010864391922950745\nEpoch:  437\nError:  0.007566246669739485\nEpoch:  438\nError:  0.0005504761938937008\nEpoch:  439\nError:  0.148905947804451\nEpoch:  440\nError:  0.0005172345554456115\nEpoch:  441\nError:  0.0031565623357892036\nEpoch:  442\nError:  0.007372908294200897\nEpoch:  443\nError:  0.0007566926069557667\nEpoch:  444\nError:  0.0008036244544200599\nEpoch:  445\nError:  0.0009559590835124254\nEpoch:  446\nError:  0.004287931136786938\nEpoch:  447\nError:  0.009877022355794907\nEpoch:  448\nError:  0.0002022777043748647\nEpoch:  449\nError:  0.03787235915660858\nEpoch:  450\nError:  0.00034231049357913435\nEpoch:  451\nError:  0.011884479783475399\nEpoch:  452\nError:  0.0029627259355038404\nEpoch:  453\nError:  0.002102547325193882\nEpoch:  454\nError:  0.0005062728887423873\nEpoch:  455\nError:  0.004435700364410877\nEpoch:  456\nError:  0.0008621074957773089\nEpoch:  457\nError:  0.013973145745694637\nEpoch:  458\nError:  0.016634106636047363\nEpoch:  459\nError:  0.004917550832033157\nEpoch:  460\nError:  0.011393364518880844\nEpoch:  461\nError:  0.005877118557691574\nEpoch:  462\nError:  0.005741058848798275\nEpoch:  463\nError:  0.01003459095954895\nEpoch:  464\nError:  0.00019167017308063805\nEpoch:  465\nError:  0.0005279577453620732\nEpoch:  466\nError:  0.008332724682986736\nEpoch:  467\nError:  0.00416661286726594\nEpoch:  468\nError:  0.0004825619689654559\nEpoch:  469\nError:  0.018142936751246452\nEpoch:  470\nError:  0.0004757702990900725\nEpoch:  471\nError:  0.0032858450431376696\nEpoch:  472\nError:  0.01011967845261097\nEpoch:  473\nError:  0.0004857790481764823\nEpoch:  474\nError:  0.01003683265298605\nEpoch:  475\nError:  0.00030191155383363366\nEpoch:  476\nError:  0.002453890163451433\nEpoch:  477\nError:  0.0008927173912525177\nEpoch:  478\nError:  0.0005596501869149506\nEpoch:  479\nError:  0.011247209273278713\nEpoch:  480\nError:  0.0013954435708001256\nEpoch:  481\nError:  0.0019733496010303497\nEpoch:  482\nError:  0.0014391313306987286\nEpoch:  483\nError:  0.0064749447628855705\nEpoch:  484\nError:  0.002795242937281728\nEpoch:  485\nError:  0.0007989790174178779\nEpoch:  486\nError:  0.0023255704436451197\nEpoch:  487\nError:  0.005189401097595692\nEpoch:  488\nError:  0.002110398607328534\nEpoch:  489\nError:  0.029277145862579346\nEpoch:  490\nError:  0.00960290152579546\nEpoch:  491\nError:  0.008869772776961327\nEpoch:  492\nError:  0.0033620046451687813\nEpoch:  493\nError:  0.002275260630995035\nEpoch:  494\nError:  0.05010566487908363\nEpoch:  495\nError:  0.010882670059800148\nEpoch:  496\nError:  0.0011532806092873216\nEpoch:  497\nError:  0.0062097227200865746\nEpoch:  498\nError:  0.0009728704462759197\nEpoch:  499\nError:  0.010051349177956581\n","output_type":"stream"}]},{"cell_type":"code","source":"\ncorrect = 0\ntotal = 0\nfor i in range(len(Xvalid)):\n    Xvalid[i] = Xvalid[i].to(G_Cdevice)\n    yvalid[i] = yvalid[i].to(G_Cdevice)\n    outputs = modelR.forward(Xvalid[i].unsqueeze(0))\n    _, predicted = torch.max(outputs.data, 1)\n    total += yvalid[i].size(0)\n    correct += (predicted == yvalid[i].to(G_Cdevice)).sum().item()\n   # del images, labels, outputs\n\nprint('Accuracy on validation images: {} %'\n      .format(100 * correct / total)) ","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:19:31.628363Z","iopub.execute_input":"2022-12-22T19:19:31.628656Z","iopub.status.idle":"2022-12-22T19:19:33.952960Z","shell.execute_reply.started":"2022-12-22T19:19:31.628628Z","shell.execute_reply":"2022-12-22T19:19:33.951082Z"},"trusted":true},"execution_count":234,"outputs":[{"name":"stdout","text":"Accuracy on validation images: 100.0 %\n","output_type":"stream"}]},{"cell_type":"code","source":"# Xtest = ([i[0] for i in testing])\n# img=Xtest[4]\n# img = img.permute(-2,1).numpy()\n# plt.imshow(img)\n# print(ytrain[4])","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:19:33.954354Z","iopub.execute_input":"2022-12-22T19:19:33.954770Z","iopub.status.idle":"2022-12-22T19:19:33.959286Z","shell.execute_reply.started":"2022-12-22T19:19:33.954735Z","shell.execute_reply":"2022-12-22T19:19:33.958210Z"},"trusted":true},"execution_count":235,"outputs":[]},{"cell_type":"code","source":"# global output \n\n# for i in range(len(Xtest)):\n#     Xtest[i] = Xtest[i].to(G_Cdevice)\n#     outputs = modelR.forward(Xtest[i].unsqueeze(0))\n#     _, predicted = torch.max(outputs.data, 1)\noutputPred = []\nimageName = []\n\nfor img in tqdm(os.listdir(test_dir)): \n    path = os.path.join(test_dir, img)\n    imageName.append(img)\n    img_data = im.open(path)\n    preproceses = preproces()\n    img_data = preproceses(img_data)\n    img_data = img_data.to(G_Cdevice)\n    outputs = modelR.forward(img_data.unsqueeze(0))\n    _, predicted = torch.max(outputs.data, 1)\n    outputPred.append(predicted.item())\n\n# for i in range(len(testing)):\n#     testing[i] = testing[i].to(G_Cdevice)\n#     outputs = modelR.forward(testing[i].unsqueeze(0))\n#     _, predicted = torch.max(outputs.data, 1)\n# #     print(predicted.item())\n#     outputPred.append(predicted.item())\n#     imageName.append(str(i)+'.jpg')","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:19:33.961084Z","iopub.execute_input":"2022-12-22T19:19:33.961764Z","iopub.status.idle":"2022-12-22T19:19:48.656045Z","shell.execute_reply.started":"2022-12-22T19:19:33.961727Z","shell.execute_reply":"2022-12-22T19:19:48.655082Z"},"trusted":true},"execution_count":236,"outputs":[{"name":"stderr","text":"100%|██████████| 688/688 [00:14<00:00, 46.88it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.DataFrame()\ndata['image_name'] = imageName\ndata['label'] = outputPred\n#data.to_csv(\"team11_CS.csv\")\ndata.to_csv('team11_CS.csv', index=False)\n\ndata","metadata":{"execution":{"iopub.status.busy":"2022-12-22T19:19:48.657335Z","iopub.execute_input":"2022-12-22T19:19:48.658121Z","iopub.status.idle":"2022-12-22T19:19:48.677625Z","shell.execute_reply.started":"2022-12-22T19:19:48.658077Z","shell.execute_reply":"2022-12-22T19:19:48.676597Z"},"trusted":true},"execution_count":237,"outputs":[{"execution_count":237,"output_type":"execute_result","data":{"text/plain":"    image_name  label\n0      623.jpg      4\n1      208.jpg      5\n2      473.jpg      0\n3      333.jpg      1\n4      537.jpg      1\n..         ...    ...\n683    364.jpg      3\n684     90.jpg      3\n685    599.jpg      4\n686     25.jpg      1\n687    147.jpg      3\n\n[688 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>623.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>208.jpg</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>473.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>537.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>683</th>\n      <td>364.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>684</th>\n      <td>90.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>685</th>\n      <td>599.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>686</th>\n      <td>25.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>687</th>\n      <td>147.jpg</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>688 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}